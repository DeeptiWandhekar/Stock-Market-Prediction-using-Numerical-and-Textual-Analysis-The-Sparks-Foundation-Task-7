{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGfo3BaqXTHI"
   },
   "source": [
    "\n",
    "# THE SPARKS FOUNDATION\n",
    "\n",
    "\n",
    "# AUTHOR- DEEPTI DILIP WANDHEKAR\n",
    "\n",
    "\n",
    "# TASK 7 - Stock Market Prediction using Numerical and Textual Analysis\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives:\n",
    "\n",
    "● Create a hybrid model for stock performance prediction using numerical analysis of historical stock prices and sentimental anlaysis of news headline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jqot9S3ZQbq"
   },
   "source": [
    "# Importing the package and module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6v4r-UC33DFm",
    "outputId": "8cc5a0fb-a430-40ed-f020-c4023d0f7807"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Deepti\n",
      "[nltk_data]     Wandhekar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Deepti\n",
      "[nltk_data]     Wandhekar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "4EUxdUEnEeeJ",
    "outputId": "9f88653f-10d4-427d-a38a-eec656123fed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>41883.089844</td>\n",
       "      <td>41994.261719</td>\n",
       "      <td>41770.898438</td>\n",
       "      <td>41952.628906</td>\n",
       "      <td>41952.628906</td>\n",
       "      <td>14100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>41969.859375</td>\n",
       "      <td>41969.859375</td>\n",
       "      <td>41648.109375</td>\n",
       "      <td>41872.730469</td>\n",
       "      <td>41872.730469</td>\n",
       "      <td>6100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>41924.738281</td>\n",
       "      <td>42059.449219</td>\n",
       "      <td>41812.281250</td>\n",
       "      <td>41932.558594</td>\n",
       "      <td>41932.558594</td>\n",
       "      <td>6600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>41929.019531</td>\n",
       "      <td>42063.929688</td>\n",
       "      <td>41850.289063</td>\n",
       "      <td>41945.371094</td>\n",
       "      <td>41945.371094</td>\n",
       "      <td>9500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>42263.000000</td>\n",
       "      <td>42273.871094</td>\n",
       "      <td>41503.371094</td>\n",
       "      <td>41528.910156</td>\n",
       "      <td>41528.910156</td>\n",
       "      <td>7500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>48464.910156</td>\n",
       "      <td>48854.339844</td>\n",
       "      <td>48365.578125</td>\n",
       "      <td>48782.511719</td>\n",
       "      <td>48782.511719</td>\n",
       "      <td>22200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>49252.308594</td>\n",
       "      <td>49303.789063</td>\n",
       "      <td>48956.378906</td>\n",
       "      <td>49269.320313</td>\n",
       "      <td>49269.320313</td>\n",
       "      <td>21200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>49228.261719</td>\n",
       "      <td>49569.140625</td>\n",
       "      <td>49079.570313</td>\n",
       "      <td>49517.109375</td>\n",
       "      <td>49517.109375</td>\n",
       "      <td>12700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>49763.929688</td>\n",
       "      <td>49795.191406</td>\n",
       "      <td>49073.851563</td>\n",
       "      <td>49492.320313</td>\n",
       "      <td>49492.320313</td>\n",
       "      <td>27200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>49432.828125</td>\n",
       "      <td>49663.578125</td>\n",
       "      <td>49182.371094</td>\n",
       "      <td>49584.160156</td>\n",
       "      <td>49584.160156</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date          Open          High           Low         Close  \\\n",
       "0    2020-01-14  41883.089844  41994.261719  41770.898438  41952.628906   \n",
       "1    2020-01-15  41969.859375  41969.859375  41648.109375  41872.730469   \n",
       "2    2020-01-16  41924.738281  42059.449219  41812.281250  41932.558594   \n",
       "3    2020-01-17  41929.019531  42063.929688  41850.289063  41945.371094   \n",
       "4    2020-01-20  42263.000000  42273.871094  41503.371094  41528.910156   \n",
       "..          ...           ...           ...           ...           ...   \n",
       "247  2021-01-08  48464.910156  48854.339844  48365.578125  48782.511719   \n",
       "248  2021-01-11  49252.308594  49303.789063  48956.378906  49269.320313   \n",
       "249  2021-01-12  49228.261719  49569.140625  49079.570313  49517.109375   \n",
       "250  2021-01-13  49763.929688  49795.191406  49073.851563  49492.320313   \n",
       "251  2021-01-14  49432.828125  49663.578125  49182.371094  49584.160156   \n",
       "\n",
       "        Adj Close   Volume  \n",
       "0    41952.628906  14100.0  \n",
       "1    41872.730469   6100.0  \n",
       "2    41932.558594   6600.0  \n",
       "3    41945.371094   9500.0  \n",
       "4    41528.910156   7500.0  \n",
       "..            ...      ...  \n",
       "247  48782.511719  22200.0  \n",
       "248  49269.320313  21200.0  \n",
       "249  49517.109375  12700.0  \n",
       "250  49492.320313  27200.0  \n",
       "251  49584.160156      0.0  \n",
       "\n",
       "[252 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prices = pd.read_csv(r'C:\\Users\\Deepti Wandhekar\\Desktop\\task 7\\data\\BSESN.csv')\n",
    "df_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "FPIr2r4QdRGu",
    "outputId": "27d94e5c-a440-465d-f1b9-1b82e094ad42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>News</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200101</td>\n",
       "      <td>life-style.events</td>\n",
       "      <td>Happy New Year 2020: Images; Quotes; Wishes; M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200101</td>\n",
       "      <td>city.bhubaneswar</td>\n",
       "      <td>Bone-clling cold wavecontinues to sweep state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200101</td>\n",
       "      <td>city.hyderabad</td>\n",
       "      <td>T gained 163 sq km forest cover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200101</td>\n",
       "      <td>city.hyderabad</td>\n",
       "      <td>Draft electoral rolls published</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200101</td>\n",
       "      <td>city.koc</td>\n",
       "      <td>Invasive species increasing in Kerala's core f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90868</th>\n",
       "      <td>20200630</td>\n",
       "      <td>gadgets-news</td>\n",
       "      <td>why tiktok removed 1 65 crore videos in india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90869</th>\n",
       "      <td>20200630</td>\n",
       "      <td>entertainment.ndi.bollywood</td>\n",
       "      <td>apurva asrani calls alia bhatts mother soni ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90870</th>\n",
       "      <td>20200630</td>\n",
       "      <td>entertainment.ndi.bollywood</td>\n",
       "      <td>kangana ranaut gets a doll version of herself ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90871</th>\n",
       "      <td>20200630</td>\n",
       "      <td>entertainment.ndi.bollywood</td>\n",
       "      <td>meezaan jaffrey reminisces s cldhood days with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90872</th>\n",
       "      <td>20200630</td>\n",
       "      <td>entertainment.telugu.movies.news</td>\n",
       "      <td>prabhas20 titled as radhe shyam prabhas and po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90873 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date                          Category  \\\n",
       "0      20200101                 life-style.events   \n",
       "1      20200101                  city.bhubaneswar   \n",
       "2      20200101                    city.hyderabad   \n",
       "3      20200101                    city.hyderabad   \n",
       "4      20200101                          city.koc   \n",
       "...         ...                               ...   \n",
       "90868  20200630                      gadgets-news   \n",
       "90869  20200630       entertainment.ndi.bollywood   \n",
       "90870  20200630       entertainment.ndi.bollywood   \n",
       "90871  20200630       entertainment.ndi.bollywood   \n",
       "90872  20200630  entertainment.telugu.movies.news   \n",
       "\n",
       "                                                    News  \n",
       "0      Happy New Year 2020: Images; Quotes; Wishes; M...  \n",
       "1          Bone-clling cold wavecontinues to sweep state  \n",
       "2                        T gained 163 sq km forest cover  \n",
       "3                        Draft electoral rolls published  \n",
       "4      Invasive species increasing in Kerala's core f...  \n",
       "...                                                  ...  \n",
       "90868      why tiktok removed 1 65 crore videos in india  \n",
       "90869  apurva asrani calls alia bhatts mother soni ra...  \n",
       "90870  kangana ranaut gets a doll version of herself ...  \n",
       "90871  meezaan jaffrey reminisces s cldhood days with...  \n",
       "90872  prabhas20 titled as radhe shyam prabhas and po...  \n",
       "\n",
       "[90873 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Date','Category','News']\n",
    "df_news = pd.read_csv(r'C:\\Users\\Deepti Wandhekar\\Desktop\\task 7\\data\\india-news-headlines.csv', names = cols)\n",
    "df_news = df_news.dropna(axis = 0, how ='any') \n",
    "df_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suUYrOj7bHi3"
   },
   "source": [
    "## Cleaning and Pre-processing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Tp3NSpsgeMib"
   },
   "outputs": [],
   "source": [
    "# Dropping 0 values, and the Category column as we don't require this for our analysis.\n",
    "df_news.drop(0, inplace=True)\n",
    "df_news.drop('Category', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "PVowb1Qm2ezi",
    "outputId": "784dcee0-af3f-44ee-9ae5-e565a1a5806c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>41883.089844</td>\n",
       "      <td>41994.261719</td>\n",
       "      <td>41770.898438</td>\n",
       "      <td>41952.628906</td>\n",
       "      <td>41952.628906</td>\n",
       "      <td>14100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>41969.859375</td>\n",
       "      <td>41969.859375</td>\n",
       "      <td>41648.109375</td>\n",
       "      <td>41872.730469</td>\n",
       "      <td>41872.730469</td>\n",
       "      <td>6100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>41924.738281</td>\n",
       "      <td>42059.449219</td>\n",
       "      <td>41812.281250</td>\n",
       "      <td>41932.558594</td>\n",
       "      <td>41932.558594</td>\n",
       "      <td>6600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>41929.019531</td>\n",
       "      <td>42063.929688</td>\n",
       "      <td>41850.289063</td>\n",
       "      <td>41945.371094</td>\n",
       "      <td>41945.371094</td>\n",
       "      <td>9500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>42263.000000</td>\n",
       "      <td>42273.871094</td>\n",
       "      <td>41503.371094</td>\n",
       "      <td>41528.910156</td>\n",
       "      <td>41528.910156</td>\n",
       "      <td>7500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>48464.910156</td>\n",
       "      <td>48854.339844</td>\n",
       "      <td>48365.578125</td>\n",
       "      <td>48782.511719</td>\n",
       "      <td>48782.511719</td>\n",
       "      <td>22200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>49252.308594</td>\n",
       "      <td>49303.789063</td>\n",
       "      <td>48956.378906</td>\n",
       "      <td>49269.320313</td>\n",
       "      <td>49269.320313</td>\n",
       "      <td>21200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>49228.261719</td>\n",
       "      <td>49569.140625</td>\n",
       "      <td>49079.570313</td>\n",
       "      <td>49517.109375</td>\n",
       "      <td>49517.109375</td>\n",
       "      <td>12700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>49763.929688</td>\n",
       "      <td>49795.191406</td>\n",
       "      <td>49073.851563</td>\n",
       "      <td>49492.320313</td>\n",
       "      <td>49492.320313</td>\n",
       "      <td>27200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>49432.828125</td>\n",
       "      <td>49663.578125</td>\n",
       "      <td>49182.371094</td>\n",
       "      <td>49584.160156</td>\n",
       "      <td>49584.160156</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date          Open          High           Low         Close  \\\n",
       "0   2020-01-14  41883.089844  41994.261719  41770.898438  41952.628906   \n",
       "1   2020-01-15  41969.859375  41969.859375  41648.109375  41872.730469   \n",
       "2   2020-01-16  41924.738281  42059.449219  41812.281250  41932.558594   \n",
       "3   2020-01-17  41929.019531  42063.929688  41850.289063  41945.371094   \n",
       "4   2020-01-20  42263.000000  42273.871094  41503.371094  41528.910156   \n",
       "..         ...           ...           ...           ...           ...   \n",
       "247 2021-01-08  48464.910156  48854.339844  48365.578125  48782.511719   \n",
       "248 2021-01-11  49252.308594  49303.789063  48956.378906  49269.320313   \n",
       "249 2021-01-12  49228.261719  49569.140625  49079.570313  49517.109375   \n",
       "250 2021-01-13  49763.929688  49795.191406  49073.851563  49492.320313   \n",
       "251 2021-01-14  49432.828125  49663.578125  49182.371094  49584.160156   \n",
       "\n",
       "        Adj Close   Volume  \n",
       "0    41952.628906  14100.0  \n",
       "1    41872.730469   6100.0  \n",
       "2    41932.558594   6600.0  \n",
       "3    41945.371094   9500.0  \n",
       "4    41528.910156   7500.0  \n",
       "..            ...      ...  \n",
       "247  48782.511719  22200.0  \n",
       "248  49269.320313  21200.0  \n",
       "249  49517.109375  12700.0  \n",
       "250  49492.320313  27200.0  \n",
       "251  49584.160156      0.0  \n",
       "\n",
       "[252 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting 'Date' columns from both our dataframes to type datetime\n",
    "df_news['Date'] = pd.to_datetime(df_news['Date'],format= '%Y%m%d')\n",
    "df_prices['Date'] = pd.to_datetime(df_prices['Date'])\n",
    "df_prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "qzI3u7KJ2lVP",
    "outputId": "b54412ac-630b-426f-d93e-877e00c9bc71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>News</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Bone-clling cold wavecontinues to sweep state ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>Horoscope Today; 02 January 2020: Read predict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>Bank Holidays in 2020 Mazya Navryac Bayko upda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>Mamta Mohandas plays a nurse in Lalbagh Tolly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>Homing in on 2020 Beauty in blue Live it up in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>Containment zone residents slam gh prices char...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2020-06-27</td>\n",
       "      <td>like me i wont let you have a toxic relationsp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2020-06-28</td>\n",
       "      <td>Atanu Ghosh plans to rewrite old scripts to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>6 hot and stylish bikini looks of Katrina Kaif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>Detective Byomkesh Bakshy! Edge of Tomorrow Fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                               News\n",
       "0   2020-01-01  Bone-clling cold wavecontinues to sweep state ...\n",
       "1   2020-01-02  Horoscope Today; 02 January 2020: Read predict...\n",
       "2   2020-01-03  Bank Holidays in 2020 Mazya Navryac Bayko upda...\n",
       "3   2020-01-04  Mamta Mohandas plays a nurse in Lalbagh Tolly ...\n",
       "4   2020-01-05  Homing in on 2020 Beauty in blue Live it up in...\n",
       "..         ...                                                ...\n",
       "177 2020-06-26  Containment zone residents slam gh prices char...\n",
       "178 2020-06-27  like me i wont let you have a toxic relationsp...\n",
       "179 2020-06-28  Atanu Ghosh plans to rewrite old scripts to ma...\n",
       "180 2020-06-29  6 hot and stylish bikini looks of Katrina Kaif...\n",
       "181 2020-06-30  Detective Byomkesh Bakshy! Edge of Tomorrow Fi...\n",
       "\n",
       "[182 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news['News'] = df_news.groupby(['Date']).transform(lambda x : ' '.join(x)) \n",
    "df_news = df_news.drop_duplicates() \n",
    "df_news.reset_index(inplace = True, drop = True)\n",
    "df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4jxMFBGx2qJw",
    "outputId": "848d478a-9a5b-4b90-d7ab-edcc6581b276"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n"
     ]
    }
   ],
   "source": [
    "# Cleaning headlines\n",
    "c = []\n",
    "\n",
    "for i in range(0,len(df_news['News'])):\n",
    "    news = re.sub('[^a-zA-Z]',' ',df_news['News'][i])\n",
    "    news = news.lower()\n",
    "    news = news.split()\n",
    "    news = [ps.stem(word) for word in news if not word in set(stopwords.words('english'))]\n",
    "    print(i)\n",
    "    news=' '.join(news)\n",
    "    c.append(news)    \n",
    "    # news = [word for word in news if word not in set(stopwords.words('english'))]\n",
    "    # print(news)\n",
    "    # news = []\n",
    "    # for w in news: news.append(ps.stem(w))\n",
    "    # print(news)\n",
    "    # news=' '.join(news)\n",
    "    # print(news)\n",
    "    # c.append(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "80NywnJy2q6u",
    "outputId": "559b787d-bcbf-4a5e-8f95-bab03f8dcac2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEEPTI~1\\AppData\\Local\\Temp/ipykernel_21868/71273463.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_news['News'] = pd.Series(c)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>News</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>bone clling cold wavecontinu sweep state gain ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>horoscop today januari read predict ari tauru ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>bank holiday mazya navryac bayko updat januari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>mamta mohanda play nurs lalbagh tolli celeb op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>home beauti blue live diet induc sound sleep y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>contain zone resid slam gh price charg veget v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2020-06-27</td>\n",
       "      <td>like wont let toxic relationsp food major ravi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2020-06-28</td>\n",
       "      <td>atanu ghosh plan rewrit old script make relev ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>hot stylish bikini look katrina kaif anna eden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>detect byomkesh bakshi edg tomorrow first look...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                               News\n",
       "0   2020-01-01  bone clling cold wavecontinu sweep state gain ...\n",
       "1   2020-01-02  horoscop today januari read predict ari tauru ...\n",
       "2   2020-01-03  bank holiday mazya navryac bayko updat januari...\n",
       "3   2020-01-04  mamta mohanda play nurs lalbagh tolli celeb op...\n",
       "4   2020-01-05  home beauti blue live diet induc sound sleep y...\n",
       "..         ...                                                ...\n",
       "177 2020-06-26  contain zone resid slam gh price charg veget v...\n",
       "178 2020-06-27  like wont let toxic relationsp food major ravi...\n",
       "179 2020-06-28  atanu ghosh plan rewrit old script make relev ...\n",
       "180 2020-06-29  hot stylish bikini look katrina kaif anna eden...\n",
       "181 2020-06-30  detect byomkesh bakshi edg tomorrow first look...\n",
       "\n",
       "[182 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news['News'] = pd.Series(c)\n",
    "df_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGKd6qvAcIUh"
   },
   "source": [
    "## Calculating Subjectivity and Polarity scores using TextBlob module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "9o0yogHo221J"
   },
   "outputs": [],
   "source": [
    "#Functions to get the subjectivity and polarity\n",
    "def getSubjectivity(text):\n",
    "  return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "def getPolarity(text):\n",
    "  return  TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "id": "oHeo3Wgd24i5",
    "outputId": "54afd952-3a5f-4096-f1b5-6ad9626494a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEEPTI~1\\AppData\\Local\\Temp/ipykernel_21868/1226800301.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_news['Subjectivity'] = df_news['News'].apply(getSubjectivity)\n",
      "C:\\Users\\DEEPTI~1\\AppData\\Local\\Temp/ipykernel_21868/1226800301.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_news['Polarity'] = df_news['News'].apply(getPolarity)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>News</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>bone clling cold wavecontinu sweep state gain ...</td>\n",
       "      <td>0.407322</td>\n",
       "      <td>0.040349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>horoscop today januari read predict ari tauru ...</td>\n",
       "      <td>0.410638</td>\n",
       "      <td>0.078692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>bank holiday mazya navryac bayko updat januari...</td>\n",
       "      <td>0.370711</td>\n",
       "      <td>0.085875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>mamta mohanda play nurs lalbagh tolli celeb op...</td>\n",
       "      <td>0.389496</td>\n",
       "      <td>0.126830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>home beauti blue live diet induc sound sleep y...</td>\n",
       "      <td>0.350895</td>\n",
       "      <td>0.093071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>contain zone resid slam gh price charg veget v...</td>\n",
       "      <td>0.324106</td>\n",
       "      <td>0.066983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2020-06-27</td>\n",
       "      <td>like wont let toxic relationsp food major ravi...</td>\n",
       "      <td>0.371791</td>\n",
       "      <td>0.063043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2020-06-28</td>\n",
       "      <td>atanu ghosh plan rewrit old script make relev ...</td>\n",
       "      <td>0.368076</td>\n",
       "      <td>0.054104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>hot stylish bikini look katrina kaif anna eden...</td>\n",
       "      <td>0.370906</td>\n",
       "      <td>0.061918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>detect byomkesh bakshi edg tomorrow first look...</td>\n",
       "      <td>0.345426</td>\n",
       "      <td>0.056202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                               News  \\\n",
       "0   2020-01-01  bone clling cold wavecontinu sweep state gain ...   \n",
       "1   2020-01-02  horoscop today januari read predict ari tauru ...   \n",
       "2   2020-01-03  bank holiday mazya navryac bayko updat januari...   \n",
       "3   2020-01-04  mamta mohanda play nurs lalbagh tolli celeb op...   \n",
       "4   2020-01-05  home beauti blue live diet induc sound sleep y...   \n",
       "..         ...                                                ...   \n",
       "177 2020-06-26  contain zone resid slam gh price charg veget v...   \n",
       "178 2020-06-27  like wont let toxic relationsp food major ravi...   \n",
       "179 2020-06-28  atanu ghosh plan rewrit old script make relev ...   \n",
       "180 2020-06-29  hot stylish bikini look katrina kaif anna eden...   \n",
       "181 2020-06-30  detect byomkesh bakshi edg tomorrow first look...   \n",
       "\n",
       "     Subjectivity  Polarity  \n",
       "0        0.407322  0.040349  \n",
       "1        0.410638  0.078692  \n",
       "2        0.370711  0.085875  \n",
       "3        0.389496  0.126830  \n",
       "4        0.350895  0.093071  \n",
       "..            ...       ...  \n",
       "177      0.324106  0.066983  \n",
       "178      0.371791  0.063043  \n",
       "179      0.368076  0.054104  \n",
       "180      0.370906  0.061918  \n",
       "181      0.345426  0.056202  \n",
       "\n",
       "[182 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding subjectivity and polarity columns\n",
    "df_news['Subjectivity'] = df_news['News'].apply(getSubjectivity)\n",
    "df_news['Polarity'] = df_news['News'].apply(getPolarity)\n",
    "df_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rArXz_sXcZvR"
   },
   "source": [
    "## Carrying out Sentimental Analysis on the News Headlines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 844
    },
    "id": "fkaiMxwe3K09",
    "outputId": "aafa789e-fe66-4b17-fccd-c328d8c49199"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEEPTI~1\\AppData\\Local\\Temp/ipykernel_21868/2572001898.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_news['Compound'] = [sia.polarity_scores(v)['compound'] for v in df_news['News']]\n",
      "C:\\Users\\DEEPTI~1\\AppData\\Local\\Temp/ipykernel_21868/2572001898.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_news['Negative'] = [sia.polarity_scores(v)['neg'] for v in df_news['News']]\n",
      "C:\\Users\\DEEPTI~1\\AppData\\Local\\Temp/ipykernel_21868/2572001898.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_news['Neutral'] = [sia.polarity_scores(v)['neu'] for v in df_news['News']]\n",
      "C:\\Users\\DEEPTI~1\\AppData\\Local\\Temp/ipykernel_21868/2572001898.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_news['Positive'] = [sia.polarity_scores(v)['pos'] for v in df_news['News']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>News</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>bone clling cold wavecontinu sweep state gain ...</td>\n",
       "      <td>0.407322</td>\n",
       "      <td>0.040349</td>\n",
       "      <td>-0.9998</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>horoscop today januari read predict ari tauru ...</td>\n",
       "      <td>0.410638</td>\n",
       "      <td>0.078692</td>\n",
       "      <td>-0.9998</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>bank holiday mazya navryac bayko updat januari...</td>\n",
       "      <td>0.370711</td>\n",
       "      <td>0.085875</td>\n",
       "      <td>-0.9994</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>mamta mohanda play nurs lalbagh tolli celeb op...</td>\n",
       "      <td>0.389496</td>\n",
       "      <td>0.126830</td>\n",
       "      <td>-0.9998</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>home beauti blue live diet induc sound sleep y...</td>\n",
       "      <td>0.350895</td>\n",
       "      <td>0.093071</td>\n",
       "      <td>-0.9999</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>contain zone resid slam gh price charg veget v...</td>\n",
       "      <td>0.324106</td>\n",
       "      <td>0.066983</td>\n",
       "      <td>-0.9998</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2020-06-27</td>\n",
       "      <td>like wont let toxic relationsp food major ravi...</td>\n",
       "      <td>0.371791</td>\n",
       "      <td>0.063043</td>\n",
       "      <td>-0.9998</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2020-06-28</td>\n",
       "      <td>atanu ghosh plan rewrit old script make relev ...</td>\n",
       "      <td>0.368076</td>\n",
       "      <td>0.054104</td>\n",
       "      <td>-0.9998</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>hot stylish bikini look katrina kaif anna eden...</td>\n",
       "      <td>0.370906</td>\n",
       "      <td>0.061918</td>\n",
       "      <td>-0.9998</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>detect byomkesh bakshi edg tomorrow first look...</td>\n",
       "      <td>0.345426</td>\n",
       "      <td>0.056202</td>\n",
       "      <td>-0.9999</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                               News  \\\n",
       "0   2020-01-01  bone clling cold wavecontinu sweep state gain ...   \n",
       "1   2020-01-02  horoscop today januari read predict ari tauru ...   \n",
       "2   2020-01-03  bank holiday mazya navryac bayko updat januari...   \n",
       "3   2020-01-04  mamta mohanda play nurs lalbagh tolli celeb op...   \n",
       "4   2020-01-05  home beauti blue live diet induc sound sleep y...   \n",
       "..         ...                                                ...   \n",
       "177 2020-06-26  contain zone resid slam gh price charg veget v...   \n",
       "178 2020-06-27  like wont let toxic relationsp food major ravi...   \n",
       "179 2020-06-28  atanu ghosh plan rewrit old script make relev ...   \n",
       "180 2020-06-29  hot stylish bikini look katrina kaif anna eden...   \n",
       "181 2020-06-30  detect byomkesh bakshi edg tomorrow first look...   \n",
       "\n",
       "     Subjectivity  Polarity  Compound  Negative  Neutral  Positive  \n",
       "0        0.407322  0.040349   -0.9998     0.151    0.777     0.071  \n",
       "1        0.410638  0.078692   -0.9998     0.155    0.766     0.079  \n",
       "2        0.370711  0.085875   -0.9994     0.122    0.790     0.088  \n",
       "3        0.389496  0.126830   -0.9998     0.146    0.780     0.074  \n",
       "4        0.350895  0.093071   -0.9999     0.156    0.772     0.072  \n",
       "..            ...       ...       ...       ...      ...       ...  \n",
       "177      0.324106  0.066983   -0.9998     0.142    0.790     0.068  \n",
       "178      0.371791  0.063043   -0.9998     0.139    0.791     0.070  \n",
       "179      0.368076  0.054104   -0.9998     0.135    0.801     0.064  \n",
       "180      0.370906  0.061918   -0.9998     0.130    0.800     0.069  \n",
       "181      0.345426  0.056202   -0.9999     0.134    0.818     0.048  \n",
       "\n",
       "[182 rows x 8 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding sentiment score to df_news\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "df_news['Compound'] = [sia.polarity_scores(v)['compound'] for v in df_news['News']]\n",
    "df_news['Negative'] = [sia.polarity_scores(v)['neg'] for v in df_news['News']]\n",
    "df_news['Neutral'] = [sia.polarity_scores(v)['neu'] for v in df_news['News']]\n",
    "df_news['Positive'] = [sia.polarity_scores(v)['pos'] for v in df_news['News']]\n",
    "df_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daD24wwDcj1p"
   },
   "source": [
    "\n",
    "## We will use our **Sentimental Analysis findings** along with the historical prices data for predicting stock prices **using Multivariate Time Series Forecasting**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3W4nk2yc3LE4",
    "outputId": "97cb65d6-b510-46b3-c4bc-9fd27181032f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date          Open          High           Low         Close  \\\n",
      "0   2020-01-14  41883.089844  41994.261719  41770.898438  41952.628906   \n",
      "1   2020-01-15  41969.859375  41969.859375  41648.109375  41872.730469   \n",
      "2   2020-01-16  41924.738281  42059.449219  41812.281250  41932.558594   \n",
      "3   2020-01-17  41929.019531  42063.929688  41850.289063  41945.371094   \n",
      "4   2020-01-20  42263.000000  42273.871094  41503.371094  41528.910156   \n",
      "..         ...           ...           ...           ...           ...   \n",
      "247 2021-01-08  48464.910156  48854.339844  48365.578125  48782.511719   \n",
      "248 2021-01-11  49252.308594  49303.789063  48956.378906  49269.320313   \n",
      "249 2021-01-12  49228.261719  49569.140625  49079.570313  49517.109375   \n",
      "250 2021-01-13  49763.929688  49795.191406  49073.851563  49492.320313   \n",
      "251 2021-01-14  49432.828125  49663.578125  49182.371094  49584.160156   \n",
      "\n",
      "        Adj Close   Volume  \n",
      "0    41952.628906  14100.0  \n",
      "1    41872.730469   6100.0  \n",
      "2    41932.558594   6600.0  \n",
      "3    41945.371094   9500.0  \n",
      "4    41528.910156   7500.0  \n",
      "..            ...      ...  \n",
      "247  48782.511719  22200.0  \n",
      "248  49269.320313  21200.0  \n",
      "249  49517.109375  12700.0  \n",
      "250  49492.320313  27200.0  \n",
      "251  49584.160156      0.0  \n",
      "\n",
      "[252 rows x 7 columns]\n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Subjectivity',\n",
      "       'Polarity', 'Compound', 'Negative', 'Neutral', 'Positive'],\n",
      "      dtype='object')\n",
      "113\n",
      "252\n",
      "182\n"
     ]
    }
   ],
   "source": [
    "# Merging our findings (the updated News dataframe) with the Prices dataframe\n",
    "df_merge = pd.merge(df_prices, df_news, how='inner', on='Date')\n",
    "print(df_prices)\n",
    "df_merge.drop('Date', axis = 1, inplace=True)\n",
    "df_merge.drop('News', axis=1, inplace=True)\n",
    "print(df_merge.columns)\n",
    "print(len(df_merge))\n",
    "print(len(df_prices))\n",
    "print(len(df_news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ecrFu9_yTHtH"
   },
   "outputs": [],
   "source": [
    "# getting our data series ready for Multivariate Time Series Forecasting\n",
    "from pandas import DataFrame as df\n",
    "from pandas import concat\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf1 = df(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df1.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df1.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WfBvsX8mTM1p",
    "outputId": "1a6b161d-7580-43a2-8fca-1789a733eef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Open          High           Low         Close     Adj Close  \\\n",
      "0    41883.089844  41994.261719  41770.898438  41952.628906  41952.628906   \n",
      "1    41969.859375  41969.859375  41648.109375  41872.730469  41872.730469   \n",
      "2    41924.738281  42059.449219  41812.281250  41932.558594  41932.558594   \n",
      "3    41929.019531  42063.929688  41850.289063  41945.371094  41945.371094   \n",
      "4    42263.000000  42273.871094  41503.371094  41528.910156  41528.910156   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "108  35679.738281  35706.550781  34794.929688  34868.980469  34868.980469   \n",
      "109  34525.390625  35081.609375  34499.781250  34842.101563  34842.101563   \n",
      "110  35144.781250  35254.878906  34910.339844  35171.269531  35171.269531   \n",
      "111  34926.949219  35032.359375  34662.058594  34961.519531  34961.519531   \n",
      "112  35168.300781  35233.910156  34812.800781  34915.800781  34915.800781   \n",
      "\n",
      "      Volume  Subjectivity  Polarity  Compound  Negative  Neutral  Positive  \n",
      "0    14100.0      0.426605  0.126399   -0.9998     0.143    0.783     0.074  \n",
      "1     6100.0      0.381507  0.107825   -0.9998     0.140    0.784     0.076  \n",
      "2     6600.0      0.378463  0.124173   -0.9999     0.158    0.766     0.076  \n",
      "3     9500.0      0.397880  0.043625   -0.9999     0.172    0.760     0.067  \n",
      "4     7500.0      0.373201  0.070348   -0.9999     0.160    0.767     0.073  \n",
      "..       ...           ...       ...       ...       ...      ...       ...  \n",
      "108  26600.0      0.357032  0.074540   -0.9997     0.126    0.807     0.067  \n",
      "109  24600.0      0.355012  0.008858   -0.9999     0.152    0.796     0.052  \n",
      "110  24800.0      0.324106  0.066983   -0.9998     0.142    0.790     0.068  \n",
      "111  18300.0      0.370906  0.061918   -0.9998     0.130    0.800     0.069  \n",
      "112  18500.0      0.345426  0.056202   -0.9999     0.134    0.818     0.048  \n",
      "\n",
      "[113 rows x 12 columns]\n",
      "[[4.18830898e+04 4.19942617e+04 4.17708984e+04 ... 1.43000000e-01\n",
      "  7.83000000e-01 7.40000000e-02]\n",
      " [4.19698594e+04 4.19698594e+04 4.16481094e+04 ... 1.40000000e-01\n",
      "  7.84000000e-01 7.60000000e-02]\n",
      " [4.19247383e+04 4.20594492e+04 4.18122812e+04 ... 1.58000000e-01\n",
      "  7.66000000e-01 7.60000000e-02]\n",
      " ...\n",
      " [3.51447812e+04 3.52548789e+04 3.49103398e+04 ... 1.42000000e-01\n",
      "  7.90000000e-01 6.80000000e-02]\n",
      " [3.49269492e+04 3.50323594e+04 3.46620586e+04 ... 1.30000000e-01\n",
      "  8.00000000e-01 6.90000000e-02]\n",
      " [3.51683008e+04 3.52339102e+04 3.48128008e+04 ... 1.34000000e-01\n",
      "  8.18000000e-01 4.80000000e-02]]\n",
      "Index(['var1(t-1)', 'var2(t-1)', 'var3(t-1)', 'var4(t-1)', 'var5(t-1)',\n",
      "       'var6(t-1)', 'var7(t-1)', 'var8(t-1)', 'var9(t-1)', 'var10(t-1)',\n",
      "       'var11(t-1)', 'var12(t-1)', 'var4(t)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# scale our data for optimal performance\n",
    "values = df_merge.values\n",
    "print(df_merge)\n",
    "print(values)\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[12,13,14,16,17,18,19,20,21,22,23]], axis=1, inplace=True)\n",
    "print(reframed.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lnHts6uqgrD"
   },
   "source": [
    "### Building a **LSTM** **(Long Short Term Memory)** Model to predict Stock Prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ze9mGTcBYaxM",
    "outputId": "cdd4f22d-fd65-4301-f2f8-3d405c52bd9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 13)\n",
      "(90, 1, 12) (90,) (22, 1, 12) (22,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "print((values).shape)\n",
    "n_train_hours = 90\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "W0JIAPYrYbVc",
    "outputId": "02b392b6-e337-497e-cc19-518b1f3802bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1471, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 1, 12), found shape=(None, 12)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DEEPTI~1\\AppData\\Local\\Temp/ipykernel_21868/1027237894.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# fit network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m72\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# plot history\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1471, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 1, 12), found shape=(None, 12)\n"
     ]
    }
   ],
   "source": [
    "# design the network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam') \n",
    "\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsIZJGe6q8yp"
   },
   "source": [
    "### **Testing** the LSTM Model with the test data and calculating **RMSE(Root Mean Square Error)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQxDeAx8Ybin",
    "outputId": "5e2de18d-a9dd-4816-9650-b8e76d41a009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 12)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DEEPTI~1\\AppData\\Local\\Temp/ipykernel_21868/2508492711.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# make a prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "print(test_X.shape)\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[2]))\n",
    "print(test_X.shape)\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------END OF CODE----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THANK YOU"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOAL04RqLTngPU6/J+HBqm7",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "TSF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
